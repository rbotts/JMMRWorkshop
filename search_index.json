[
["index.html", "SIGMAA Stat Ed Mini-course for JMM 2020: Teaching Reproducible Statistics with R and R Studio Preface Welcome Purpose Outline Downloading software Who we are", " SIGMAA Stat Ed Mini-course for JMM 2020: Teaching Reproducible Statistics with R and R Studio Judith E. Canner &amp; Ryan Botts 2020-01-14 Preface Teaching Reproducible Statistics with R and R Studio Welcome R is a freely available language and environment for statistical computing and graphics that has become popular in academia and in many industries. In addition, RStudio and RMarkdown have become standard tools in reproducible analysis and reporting. This mini-course will introduce participants to teaching applied statistics courses using integrated computing to facilitate learning and develop best practices in statistical learning. The presenters will share different approaches to teaching statistics using R and some favorite examples for using R to teach statistics to undergraduates at all levels, including in introductory courses for mathematics and science majors. Topics will include simple approaches to provide novices with a powerful, but manageable, set of tools, workflow in the RStudio environment, data visualization, basic statistical inference using R, and using R Markdown to create documents that include both text and R output. This mini-course is designed to be accessible to those with little or no experience using R or teaching with R and will provide participants with skills, examples, and resources that they can use in their own teaching. Purpose The aim of this workshop is to introduce the users to beginning and intermediate uses of R, along with best practices of using R in the classroom as well as in real-world data analysis projects. We assume no prior background with R. As you learn R, we also aim to provide many practical examples of the tools we commonly use in our own work. During the workshop there are many places where optional questions are given. If you have been successful, with the code provided we encourage you to try these extra bonuses to test your abilities. Outline Day 1 Introduction to R Studio Environment Introduction to R Markdown and Reproducible Documentation Introduction to Statistics using R Markdown Data Visualization (base and ggplot2) Statistical Inference (basic inference, central limit theorem, resampling methods) Day 2 Teaching R across the Math and Stat Curriculum Pedagogy for Programming Examples, Assignments, and Projects Packages for assisting learning (e.g., mosaic, ggformula) Teaching students (and you) how to get help in R Downloading software We are excited to meet you next week and support you as you start your journey to learning R and teaching R in your classes. We do not expect anyone to have seen R before so we will structure the minicourse such that day one focuses on using R and day two focuses on teaching with R. Though the second day will emphasize teaching, we will try to model pedagogical practices for teaching R and statistics throughout the workshop. You will need your laptops and there is some prep work to do! To get you ready for the minicourse, register for the FREE course Getting Started with R and complete the first few modules on how to download and install R, R Studio, and getting started with Projects (~20 minutes). There is no need to complete the rest of the course unless you want to as only the first three lessons are necessary for the minicourse (though I recommend completing it at some point). One of the great things about R is the vibrant online community and abundance of free resources to support learning the language so we thought taking advantage of the community built resources would be a great way to welcome you to R. If you are using a tablet or perhaps you computer just doesn’t have the memory for more programs (just like our students!) sign up for an account with https://rstudio.cloud which provides free access to the RStudio environment through your internet browser. If anyone has issues getting R/RStudio installed prior to the minicourse, Ryan and I will be in the workshop room at 8:30am the first day to help troubleshoot any issues. Who we are Judith E Canner Associate Professor of Statistics, California State University, Monterey Bay Dr. Canner has been using R to teach undergraduate introductory statistics for biologists and mathematicians/statisticians since 2010. She has presented numerous times on R pedagogy in statistics courses and regularly teaches a statistical computing seminar using R, R Studio, and R Markdown. Ryan Botts Associate Professor of Mathematics, Point Loma Nazarene University Dr. Botts has been teaching R extensively to undergraduates from across many disciplines since 2014, and regularly advises students in undergraduate research using R and RShiny. Additionally, he has published on teaching pedagogy in non-major mathematics courses, including introductory statistics. "],
["rstudio-environment.html", "1 RStudio Environment 1.1 Importing data 1.2 Command line 1.3 Scripts and Notebooks 1.4 Loading Packages", " 1 RStudio Environment Here we will gain some basic familiarity with the RStudio environment. Usually the first confusion for students in using R is in actually installing it. We typically encourage students to develop and interface with R through RStudio. So let’s take a look at what RStudio has to offer. Below is an image of the typical RStudio environment. When R is opened, a workspace is created and code run from a script, at the command line or from one of the built in functions and by default is run from this workspace. 1.1 Importing data We will begin by importing a dataset posted by Merijn Coumans from a Tesla User’s Group about the battery life, charge history, location, etc. of Tesla cars. A slightly cleaned version of the data can be found cleanTeslaBattery.csv. Download this dataset and save it somewhere you can find it. On the upper right select the Import Dataset button, for this case select From Text (base). When you find the dataset, select open and you will see a new menu open. A few things to note are the “Name” box specifying the variable name assigned to the dataset, and also note the “Header” option and select appropriately depending on whether there is a header row or not. Import the data. Note what appears in the terminal. Tesla &lt;- read.csv(&quot;Data/cleanTeslaBattery.csv&quot;) View(Tesla) Teaching tip: It helps to introduce students to where they can change the name of the variable referring to the data they are reading in and the teach them to check that headers have been selected, if appropriate. For entry level students, this is an easy way to import data, but it also provides us with an example of the command that we could have manually typed to load the data, and which we can put into our script or notebook document. We will save this command for use in just a bit. Without introducing object types or anything advanced, a quick summary of the data can give some useful information and let students know if the data read in as expected. We will try that command shortly. Teaching tip: Students with Mac’s using Numbers frequently open the files they download using Numbers. Numbers adds some extra invisibles that will throw errors if the data is then loaded into R. 1.2 Command line Let’s go ahead and compute a summary of the data we just imported to double-check how R is treating each variable, e.g. categorical, quantitative, or character. summary(Tesla) Location ManufactureDate Asia Pacific &amp; Europe (excl UK):1058 2015-04-03T00:00:00Z: 46 Canada : 47 2014-06-04T00:00:00Z: 32 UK : 12 2015-06-10T00:00:00Z: 32 USA : 222 2013-09-10T00:00:00Z: 28 2013-11-20T00:00:00Z: 27 (Other) :1169 NA&#39;s : 5 ReadDate AgeInDays Model 2015-01-15T00:00:00Z: 8 Min. : 0.0 Model S 85 :475 2015-10-21T00:00:00Z: 8 1st Qu.: 252.0 Model S P85 :178 2014-09-24T00:00:00Z: 7 Median : 494.0 Model S 85D :112 2015-12-09T00:00:00Z: 7 Mean : 734.1 Model S 90D :107 2014-09-18T00:00:00Z: 6 3rd Qu.: 832.8 Model S 70D :103 2014-09-26T00:00:00Z: 6 Max. :43219.0 Model S P85D: 91 (Other) :1297 NA&#39;s :1 (Other) :273 MileageKM MileagePerDay MaxRangeKM ReplacementBatt Min. : 6 Min. : 0.70 Min. :174.0 No :1265 1st Qu.: 17838 1st Qu.: 57.40 1st Qu.:358.0 Yes: 74 Median : 39929 Median : 84.10 Median :377.0 Mean : 51325 Mean : 88.63 Mean :361.5 3rd Qu.: 69278 3rd Qu.:113.42 3rd Qu.:389.0 Max. :361500 Max. :282.90 Max. :509.0 NA&#39;s :5 NA&#39;s :1 MileageSinceNewKM BatteryAgeDays WattHoursPerKM OriginalRangeKM Min. : 6 Min. : 1.0 Min. :155.0 Min. :180.0 1st Qu.: 17687 1st Qu.: 246.0 1st Qu.:208.0 1st Qu.:365.0 Median : 39120 Median : 487.0 Median :221.0 Median :400.0 Mean : 50616 Mean : 571.2 Mean :234.8 Mean :378.8 3rd Qu.: 69182 3rd Qu.: 823.0 3rd Qu.:241.0 3rd Qu.:400.0 Max. :284500 Max. :2466.0 Max. :450.0 Max. :515.0 NA&#39;s :1 NA&#39;s :6 NA&#39;s :22 SuperchargeFreq MaxChargeFreq twice a month :357 a few times a year :503 monthly :261 monthly :346 a few times a year:240 twice a month :164 weekly :189 once or twice a year: 84 twice a week :107 weekly : 55 (Other) : 75 (Other) : 71 NA&#39;s :110 NA&#39;s :116 RunToEmptyFreq DailyChargeLevel Cycles ModelXS never :438 Min. :10.00 Min. : 0.02 3 : 4 a few times a year :347 1st Qu.:80.00 1st Qu.: 55.05 85: 24 once or twice a year:331 Median :80.00 Median :123.95 S :1277 monthly : 72 Mean :80.83 Mean :155.24 X : 34 twice a month : 27 3rd Qu.:90.00 3rd Qu.:213.89 (Other) : 9 Max. :90.00 Max. :906.37 NA&#39;s :115 NA&#39;s :279 NA&#39;s :23 ModNum 85 :475 P85 :178 90D :136 85D :112 70D :103 P85D : 91 (Other):244 Based on the summary, what can you say about how R is summarizing the age column? This is good when working with introductory students. Questions The head and tail functions allow you to inspect the first few rows or last few rows in the data. Implement one of these on your dataset. How many rows of data do you get? Try the names function on this data? What does it produce? To demonstrate the utility of R, let’s compute the mean of the Mileage column. mean(Tesla$MileageKM) [1] 51325.09 Teaching tip: this is a useful place to introduce students to case sensitivity and what happens when you forget a parentheses (You can get out of it using the Esc key.) Programmer’s note: R treats columns in a dataframe much like dictionaries in Python, as well as using matri notation like Python, Java or Matlab. Aside from the “$” operator, one can reference the row or column using numbers or names (if they have them) The code below computes the standard deviation of the same column. sd(Tesla[,&quot;MileageKM&quot;]) [1] 46712.35 Practice Try the histogram function hist and the boxplot function boxplot on one of the quantitative variables. Teaching tip: When teaching R to introductory students, make it accessible as a go to tool for completing homework the first day. Teaching tip: When importing data, frequently students will select the readr option. In many cases this won’t matter, but readr reads the data in as a tibble instead of a data frame. In many cases students won’t notice, but because of data structure of the tibble object, there are cases where downstream analysis will not behave the same, so for simplicity the base option is often easier. However, for more advanced users, tibble are often very helpful. For intro students to make it their go to tool, they often need a calculator for their homework, show how it can be done easily. Here we show how to input your own data and do some basic computations on it. dat &lt;- c(1,9,23,35) median(dat) [1] 16 Note that the command c() specifies a list that is assigned to the variable dat that can then be used for calculation later. Teaching tip: Intro. students often have a difficult time grasping that variable names are just a reference they are giving to something an that they can call that thing later on, so I often have them practice calling variables and renaming variables to help them overcome this. 1.3 Scripts and Notebooks This brings us to reproducability. One of the great strengths of R is in creating reproducible analyses. So let’s save the code we just entered so that we can run it later. First we will create a new R Script. Under file, open a new R Script. Copy the code you just entered at the terminal and past it into the script. Note that you will have to delete the “&gt;” character from each new line. Some things to know about running from scripts: The run button is the little green arrow at the top of the text editor, if you select “run selected line(s),” the line the cursor is currently on will be run, or the current selected code will be executed. Try re-running all of the code you have just entered in your script from the terminal. Notebooks are another nice way to create reproducible analyses. Under the file menu open a new notebook and you should see something like this: You will find that the R community makes getting started in many of these files quite straightforward, with many detail on how to use them in the new files. Information on notebooks will be given later. Note that the cars variable here is a pre-installed dataset that comes with R that is frequently used in examples. Teaching tip: Remind students to test what they have saved. I find that often they may run something at the command line and forget to save it, so their code won’t run from a clean workspace the next time. Question When would students want to use the command line over a notebook or a script? 1.4 Loading Packages RStudio provides easy features for package management. The lower right-hand window has a package manager. The packages listed are currently installed, while others may be installed using the Install option. Note that when you are ready to use a package you must also load it using the library() function. Try loading the ggplot2 package, which we will be using later in this workshop. Teaching Tip: Students often forget that the workspace and the variables in it use memory, so encourage them to clean up unused items in the workspace. "],
["rmarkdown-and-reproducible-documentation.html", "2 RMarkdown and Reproducible Documentation 2.1 R, RStudio, and RMarkdown 2.2 Communication with RMarkdown 2.3 Learning More about R Markdown", " 2 RMarkdown and Reproducible Documentation Twitter @Allison_Horst Introduction to R.Rmd 2.1 R, RStudio, and RMarkdown One of the benefits of using R is that is comes with its own documentation system, called RMarkdown. The distinction between R, RStudio, and RMarkdown is often blurred, but in there is a difference: R is a programming language RStudio is a writing software and GUI for using R RMarkdown an authoring format for communication At the root of everything is the R programming language, but RStudio and RMarkdown layer on additional interfaces and languages to support reproducibility of results and communication. To learn more, check out this short online resource Getting Used to R, RStudio, and RMarkdown. 2.2 Communication with RMarkdown The Markdown language has actually been around for a while. It is a markup language with plain text formatting syntax that allows it to be converted to many output formats, such as HTML. RMarkdown adapts the Markdown language and incorporates the ability to include R code and output (and other languages) seamlessly. The beauty of R Markdown is that it allows you to create reproducible reports of analysis, without copy and pasting code/output, and to export those reports into HTML, Word .docx, and PDF. RStudio Creative Commons BY-SA 4.0 Let’s watch a short video to get a better overview. R Markdown Introduction Now let’s create our first RMarkdown document! Start a new Project Download the following document and save it into your Project folder: Introduction to R.Rmd Check settings (gear) that is says “Preview in Viewer Pane” To see the output of the document, click Preview, What happened? 2.3 Learning More about R Markdown R Markdown can also be used to make presentations, tutorials, and data dashboards. To learn more, check out RMarkdown: The Definitive Guide. You can also check out the RMarkdown Cheatsheet and RMarkdown Reference Guide. "],
["teaching-r-and-statistics-together.html", "3 Teaching R and Statistics Together 3.1 The Grammar of Graphics for Data Visualization 3.2 Statistical Inference", " 3 Teaching R and Statistics Together One of the challenges for teaching R is that students want to get started right away without thinking about what the output should look like and what their goal actually is with programming. Encouraging students to stop and think will help them determine the best approach in R. 3.1 The Grammar of Graphics for Data Visualization A data visualization is a set of visual geometries whose aesthetics are mapped from data. 3.1.1 Geometry A geometry is a visual entity in space. Some common geometries encountered in data visualizations: Point Line Bar 3.1.2 Aesthetics An aesthetic is a visual attribute of a geometry Common aesthetics: Position on horizontal (X) Position on vertical (Y) Shape Size Color Hue Saturation (“intensity”) Value (“brightness”) Text https://serialmentor.com/dataviz/aesthetic-mapping.html Not all aesthetics are available for every geometry 3.1.3 Data To visualize, must have data in row-by-column format where: Rows represent cases: at most one geometry per case (assuming no aggregation) Columns represent variables: to be mapped to aesthetic attributes https://r4ds.had.co.nz/tidy-data.html#tidy-data-1 Differences in geometry aesthetics map to differences in data variables Available mappings depend on whether data variable is continuous (height) or discrete (race) The following caveats apply: An aesthetic attribute can be mapped back to at most one variable A variable can be mapped to more than one aesthetic Not all mappings make sense Students often do not recognize that a categorical variable is already summarized and confuse the count/frequency for a quantitative variable rather than a statistic. ### Visualization using base R graphics The base graphics often provide a very simple way for students to get plots quickly and explore data. We will continue using the cleanTeslaBattery data. Load it now and view it. 3.1.3.1 Histograms and boxplots One wonderful thing about R is how intuitive the functions are, if you want a mean, the command is mean, if you want a boxplot, the command is ‘boxplot’. Run the command ‘boxplot(cleanTeslaBattery$MaxRangeKM)’. You should get the following: boxplot(cleanTeslaBattery$MaxRangeKM) The x- and y-axis labels, main title, as well as color can be set using optional variables, xlab, ylab, main and color, respectively. Modify your command to boxplot(cleanTeslaBattery$MaxRangeKM, xlab = &quot;All&quot;, ylab = &quot;KM&quot;, main = &quot;Max Range&quot;, col = &quot;green&quot;). R has many other colors built in and also accepts hexadecimals. Search the web to find some other possible colors to modify your graph. Replacing boxplot() with hist will give the expected effect. Try it on one of the other quantitative variables. Note that histograms have an optional argument to control how many bins called breaks. Try adding the option ‘breaks = 50’ Set the number of breaks to 5, notice anything strange? Set your histogram to another color One other feature that is nice is that comparisons between quantitative variables can easily be done as well. Suppose we want to compare the maximum range based on how frequently they supercharge their batteries. Enter the command boxplot(MaxRangeKM ~ SuperchargeFreq, data = cleanTeslaBattery, las = 2) Note the relational notation y ~ x In many functions we can specify the data set to avoid extra typing The las argument specifies turning the axis labels 90 degrees The optional axis labels are as before Colors can still be specified, but now we need a list of colors, one for each box. Add the optional argument col = heat.colors(8). Note you must specify one for each category. There are many color palettes. You can view some with the command ?colors. Teaching tip: One of the most common problems students run into here is not putting the variables in the correct order in the ‘y ~ x’ 3.1.4 Scatterplots Scatterplots follow a very similar syntax as doing side-by-side boxplots, but using the plot function and replacing the qualitative explanatory variable with a quantitative one. Let’s explore the effect of Mileage (MileageKM) and the Maximum Range (MaxRangeKM). plot(MaxRangeKM ~ MileageKM, data = cleanTeslaBattery, col = &quot;darkblue&quot;) Note that the type of point can be controlled using the optional pch = 2 command and changing the number for different point types. Color and labels are done as before. Try adjusting your colors and labeling your plot. Another nice alternative for large data sets is the smoothScatter, however it doesn’t support the specification of data and will require explicitly referring to the x and y using the data frame name and ‘$’ symbol. Try it if you are interested. Clearly this graph shows multiple trends due to the different battery sizes, so we would want to separate these out separately for regression or use a more advanced regression model. For simplicity we are going to add a regression line without accounting for the car model. Regression lines are implemented using the following process: Fit and save the model to the data using lm() (x and y are specified as in the plot). This model is used for all other steps. Add the line to the scatterplot that has already been created using abline() applied to the model you have saved. Colors for the line can be specified as before. Summarize the model using summary(). Try it. plot(MaxRangeKM ~ MileageKM, data = cleanTeslaBattery, col = &quot;darkblue&quot;) line = lm(MaxRangeKM ~ MileageKM, data = cleanTeslaBattery) abline(line, col = &quot;red&quot;) summary(line) Call: lm(formula = MaxRangeKM ~ MileageKM, data = cleanTeslaBattery) Residuals: Min 1Q Median 3Q Max -186.380 -4.404 14.744 28.588 149.153 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.598e+02 2.389e+00 150.597 &lt;2e-16 *** MileageKM 3.313e-05 3.442e-05 0.962 0.336 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 58.81 on 1336 degrees of freedom (1 observation deleted due to missingness) Multiple R-squared: 0.0006928, Adjusted R-squared: -5.522e-05 F-statistic: 0.9262 on 1 and 1336 DF, p-value: 0.336 Teaching tip: Students frequently forget to create the plot first. The entire R chunk must be run in RMarkdown to preview the image. The correlation can be computed using the cor function. Look up how to use it using ?cor and try it. 3.1.5 Bar graphs Categorical data isn’t much harder, but does require a preprocessing step for base graphics. Let’s create a boxplot of the Supercharging Frequency. We will go straight to grouped bar plots. Let’s summarize the relationship between supercharging frequency and the location. This is done in three steps: tabulate (using table, stored as tble) compute conditional percentages (prop.table, stored as ptable) plot (barplot) Try it: tble = table(cleanTeslaBattery$SuperchargeFreq, cleanTeslaBattery$Location) ptable = prop.table(tble,2) barplot(ptable, beside = TRUE) Note the organization of the table and the relationship between the rows and columns. We can also add a legend and a location with the options legend.text = TRUE and args.legend = list(x = &quot;topright&quot;). Try adding them to your plot. Note, there are many options for the placement of the legend other than “topright” that you may want to use if the legend overlaps your bars. These include “bottomright”, “bottom”, “bottomleft”, “left”, “topleft”, “top”, “topright”, “right”, and “center.” Set the main title and colors (the number of colors should be the same as the number of rows in the table). A quick way to get the number of colors is to count the number of levels of a factor. You can replace the count with length(levels(vblname)), and substitute your ’vblname. A bar plot for a single variable can be accomplished by only passing in one variable. Try it on one of the other categorical variables. ## What is a package? Packages are collections of R functions, data, and compiled code in a well-defined format. The directory where packages are stored is called the library. R comes with a standard set of packages, called the base package. Others are available for download and installation. ![CC RStudio](Images/dataviz/packagesdiagram.png) Packages that are curated, maintained, and reviewed are stored on the CRAN (Comprehensive R Archive Network). ![CC RStudio](Images/dataviz/cran.png) Once installed, packages have to be loaded into the session to use the functions stored within the package. ![CC RStudio](Images/dataviz/Rpackages.png) If you ever need R to do something that is not obvious, there is probably a package for that. Many packages also provide vignettes or publish background and examples in the [Journal of Statistical Software](https://www.jstatsoft.org/index). One of the more popular packages of packages is thetidyverse, which includes packages such asdplyr,ggplot2, andreadrwhich make using R for data cleaning, graphics, and data science. We will explore a few of these packages today, starting withggplot2and the grammar of graphics. ## Package ggplot2 The packageggplot2stands for grammar of graphic plots. It works to layer details onto a graphic map data to specific aesthetics using specific geometries. If you have not already done so, install theggplot2` package. install.packages(&quot;ggplot2&quot;) Open up the the R Notebook for Data Visualization and follow along. Now load the package into R using either library() or require() library(ggplot2) Let’s make a graphic for the Tesla data: tesla&lt;-read.csv(&quot;Data/cleanTeslaBattery.csv&quot;) Your Turn 1 Talk in a group - what relationship do you expect to see in the tesla data between the age of the battery (Battery AgeDays) and the amount of mileage put on the car since the battery was installed (MileageSinceNewKM)? (No peeking!) Run the following code in your notebook to make a graph, paying strict attention to spelling, capitalization, and parentheses. ggplot(data=tesla) + geom_point(mapping=aes(x=BatteryAgeDays, y=MileageSinceNewKM)) Notice a few key things. ggplot(data) initializes the plot adding a + after a line of ggplot code adds a new layer start with the geometry then specify the aesthetics Here is a similar graphic code with annotation. Therefore, you can use this code template to make thousands of graphs with ggplot2. ggplot(data = &lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;)) Let’s add on some more layers! What if we want to make the variable Replacement Battery to a color aesthetic? ggplot(data=tesla) + geom_point(mapping=aes(x=BatteryAgeDays, y=MileageSinceNewKM, color=ReplacementBatt)) If we didn’t care about mapping the new variable to an aesthetic, but wanted to change the color, that would come outside of the aes() function. ggplot(data=tesla) + geom_point(mapping=aes(x=BatteryAgeDays, y=MileageSinceNewKM), color=&quot;blue&quot;) There are a lot of resources available, including a the “ggplot2 Cheatsheet” Your Turn 2 Make the following density plot, using the Cheatsheet to help you. What does the plot tell you about the Tesla driver habits in different regions? 3.1.6 Layering Graphics To get a better idea about how ggplot2 layers aesthetics and and specific geometries onto a graphic, check out the ggplot flipbook which demonstrates how each layer modifies the graphic. 3.1.7 Additional Resources There are a lot of resources for ggplot2, here are three good places to start: The data visualisation and graphics for communication chapters in R for data science. R for data science is designed to give you a comprehensive introduction to the tidyverse, and these two chapters will you get up to speed with the essentials of ggplot2 as quickly as possible. If you’d like to take an online course, try Data Visualization in R With ggplot2 by Kara Woo. If you want to dive into making common graphics as quickly as possible, I recommend The R Graphics Cookbook by Winston Chang. It provides a set of recipes to solve common graphics problems. If you’ve mastered the basics and want to learn more, read ggplot2: Elegant Graphics for Data Analysis. It describes the theoretical underpinnings of ggplot2 and shows you how all the pieces fit together. This book helps you understand the theory that underpins ggplot2, and will help you create new types of graphics specifically tailored to your needs. The book is not available for free, but you can find the complete source for the book at https://github.com/hadley/ggplot2-book. 3.2 Statistical Inference In this section we will cover some of the basic tools for statistical inference covered in an introductory statistics class. A notebook to work along is found here 3.2.1 Linear Regression Let’s go back to the Tesla Battery Data from earlier. We did linear regression when we added the regression line earlier, but now we will explore some of the other available tools with regression. cleanTeslaBattery = read.csv(&quot;Data/cleanTeslaBattery.csv&quot;) Here is a look at a scatterplot of the data library(ggplot2) ggplot(data=cleanTeslaBattery) + geom_point(aes(x=MileageKM, y=WattHoursPerKM)) Implement the linear model from before to look at the relationship between the Mileage (MileageKM) and Watt Hours Per KM (WattHoursPerKM) and assign the model to the variable mod mod = lm(WattHoursPerKM ~ MileageKM, data = cleanTeslaBattery) summary(mod) Call: lm(formula = WattHoursPerKM ~ MileageKM, data = cleanTeslaBattery) Residuals: Min 1Q Median 3Q Max -80.060 -26.278 -11.197 8.352 206.763 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.439e+02 1.743e+00 139.901 &lt; 2e-16 *** MileageKM -1.766e-04 2.500e-05 -7.063 2.63e-12 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 42.5 on 1315 degrees of freedom (22 observations deleted due to missingness) Multiple R-squared: 0.03655, Adjusted R-squared: 0.03582 F-statistic: 49.89 on 1 and 1315 DF, p-value: 2.628e-12 We can also easily inspect the residuals by calling the residual() function on the model. Try it: hist(residuals(mod)) Additionally transforms of any of the variables can be performed in the following way: lm(WattHoursPerKM ~ log(MileageKM), data = cleanTeslaBattery) Call: lm(formula = WattHoursPerKM ~ log(MileageKM), data = cleanTeslaBattery) Coefficients: (Intercept) log(MileageKM) 286.59 -5.02 lm(sqrt(WattHoursPerKM) ~ MileageKM, data = cleanTeslaBattery) Call: lm(formula = sqrt(WattHoursPerKM) ~ MileageKM, data = cleanTeslaBattery) Coefficients: (Intercept) MileageKM 1.555e+01 -5.510e-06 Finally, we left out the correlation coefficient. The call for the correlation coefficient is a little different as it doesn’t use relations cor(x,y, use = &quot;pairwise.complete.obs&quot;, method = &quot;pearson&quot;). Try the command here for the Mileage and Watt Hours Per KM. Note that the use option has been specified to omit pairs of correlations where there is an NA, and the method controls the type of correlation. 3.2.2 t-tests Here is a very quick overview of t-tests. We are going to take a look at the difference in weight gain be smoking and non-smoking mothers in Kings County. Load the dataset Kings &lt;- read.csv(&quot;Data/KingCounty2001.csv&quot;) Take a look at the relationship between smoker and wgain. boxplot(wgain ~ smoker, data = Kings ) summary(Kings$smoker) N Y 2325 175 two-sample t-test syntax follows a simple format t.test(relationship, data, type of alternative) specify the type of alternative, either “greater”, “less” or “two.tailed”, using the alternative option. t.test(wgain ~ smoker, data = Kings, alternative = &quot;greater&quot;) Welch Two Sample t-test data: wgain by smoker t = -0.65319, df = 189.21, p-value = 0.7428 alternative hypothesis: true difference in means is greater than 0 95 percent confidence interval: -3.083485 Inf sample estimates: mean in group N mean in group Y 32.21806 33.09143 Note that confidence intervals are included, but the alternative should be “two.sided.” One-sided t-tests require specifying only a single quantitative variable and also specifying the value from the null hypothesis. An example for testing that the mean wgain is different from 9.4 is t.test(Kings$wgain, mu = 9.4, alt = &quot;two.sided&quot;) One Sample t-test data: Kings$wgain t = 85.31, df = 2499, p-value &lt; 2.2e-16 alternative hypothesis: true mean is not equal to 9.4 95 percent confidence interval: 31.75331 32.80509 sample estimates: mean of x 32.2792 Other options like the conf.level are described under the help for the function. Try computing a 90% confidence interval for the mean gest. 3.2.3 Using simulation to teach reinforce concepts The R community has many powerful interactive tools written in R to help teach R. We are going to look at one of the tools offered at www.artofstat.com Here is an example of how we might use one of these to help students learn the Central Limit Theorem. These are the instructions I would give students in class: Go to the page Sampling Distribution Simulator (Art of Stats) Select on of the real population datasets. Sketch the population distribution you are shown. What are the mean and standard deviation (label appropriately)? Adjust the sample size to 5 and draw 1,000 samples. Sketch the sampling distribution. Repeat this 5 times (reset in between) sketching the sampling distribution. Record the mean and standard deviation of the sampling distribution each time. What do you observe about the sampling distribution? Adjust the sample size to 10 and draw 1,000 samples. Sketch the sampling distribution. Repeat this 5 times (reset in between) sketching the sampling distribution. Record the mean and standard deviation of the sampling distribution each time. What do you observe about the sampling distribution? Adjust the sample size to 20 and draw 1,000 samples. Sketch the sampling distribution. Repeat this 5 times (reset in between) sketching the sampling distribution. Record the mean and standard deviation of the sampling distribution each time. What do you observe about the sampling distribution? Adjust the sample size to 20 and draw 1,000 samples. Sketch the sampling distribution. Repeat this 5 times (reset in between) sketching the sampling distribution. Record the mean and standard deviation of the sampling distribution each time. What do you observe about the sampling distribution? Adjust the sample size to 100 and draw 1,000 samples. Sketch the sampling distribution. Repeat this 5 times (reset in between) sketching the sampling distribution. Record the mean and standard deviation of the sampling distribution each time. What do you observe about the sampling distribution? As you increase the sample size, what do you observe about the shape of the sampling distribution? Etc. Here is a link to the full activity 3.2.4 Tools for resampling We won’t cover this in great depth here, but we will briefly explore what can be done here: Bootstrapping app 3.2.5 Other tools commonly found in introductory statistics courses 3.2.5.1 ANOVA We demonstrated t-tests earler, and the syntax for ANOVA is quite similar. Teaching tip: When teaching non-majors incorporating data from the research of faculty teaching courses from other disciplines can increase student engagement and course relevance. For this section we are going to work with a dataset from a cancer drug development project that is part of a biology faculty member’s ongoing research at our campus, the data came from one of the student projects. Below is an image of one of the tumors. CancerTumor The measurements in the file are the percent of tumor growth under various drug treatments. Tumor.csv. Load the data now and inspect the dataset. Construct a graphical summary of your data using one of the tools from earlier. We will also construct a numerical summaries of each group using the doBy package. Install and load it now. For this I define a helper function: msd = function (x) {c(m = mean(x), stdev = sd(x))} We apply this function using summaryBy. To run an ANOVA use the command aov() by specifying the relationship and the data, as you did for summarizing the data. mod = aov(Growth ~ Treatment, data = Tumor) Note that there is something missing that most intro stats students are asked for, what is it? This can be fixed by wrapping the aov command with a summary(). Try it. Post-hoc tests can be run by saving the ANOVA model to a variable and then passing it to TukeyHSD(). Try it here: TukeyHSD(mod) Tukey multiple comparisons of means 95% family-wise confidence level Fit: aov(formula = Growth ~ Treatment, data = Tumor) $Treatment diff lwr upr p adj Control-Avastin 0.002222222 -0.029180472 0.033624916 0.9976809 Tor+Ava-Avastin -0.037222222 -0.068624916 -0.005819528 0.0137317 Torisel-Avastin -0.004444444 -0.035847138 0.026958250 0.9821827 Tor+Ava-Control -0.039444444 -0.070847138 -0.008041750 0.0080067 Torisel-Control -0.006666667 -0.038069361 0.024736027 0.9437365 Torisel-Tor+Ava 0.032777778 0.001375084 0.064180472 0.0374652 There are other functions for the other types of post-hoc tests. 3.2.6 Paired t-test Paired t-tests require data in the wide format, that is two columns side by side, perhaps like this pairdat = data.frame(pre=c(23,20,30,29),post=c(25,21,27,31)) pairdat pre post 1 23 25 2 20 21 3 30 27 4 29 31 Note this is for example only, not for validity. t.test(pairdat$pre, pairdat$post, paired=TRUE) Paired t-test data: pairdat$pre and pairdat$post t = -0.42008, df = 3, p-value = 0.7027 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -4.287869 3.287869 sample estimates: mean of the differences -0.5 3.2.6.1 Testing for Proportions For simplicity we are going to continue with the cleanTeslaBattery. Suppose we want to look at the relationship between Country and Model. Create a two-way table and a bar plot for these variables. cleanTeslaBattery = read.csv(&quot;Data/cleanTeslaBattery.csv&quot;) tbl = table(cleanTeslaBattery$Location,cleanTeslaBattery$Model) tbl Model 3 LR Model S 100D Model S 60 Asia Pacific &amp; Europe (excl UK) 0 3 22 Canada 0 0 3 UK 0 0 1 USA 4 2 20 Model S 60D Model S 70 Model S 70D Asia Pacific &amp; Europe (excl UK) 0 8 99 Canada 1 0 0 UK 1 0 0 USA 4 0 4 Model S 75 Model S 75D Model S 85 Asia Pacific &amp; Europe (excl UK) 28 20 376 Canada 1 0 20 UK 0 1 7 USA 10 7 72 Model S 85D Model S 90 Model S 90D Asia Pacific &amp; Europe (excl UK) 88 1 90 Canada 9 2 2 UK 2 0 0 USA 13 0 15 Model S 90D 2015 Model S P100D Asia Pacific &amp; Europe (excl UK) 3 8 Canada 0 0 UK 0 0 USA 10 0 Model S P85 Model S P85+ Model S P85D Asia Pacific &amp; Europe (excl UK) 141 45 75 Canada 5 1 1 UK 0 0 0 USA 32 2 15 Model S P90D Model X 100D Model X 60D Asia Pacific &amp; Europe (excl UK) 4 7 0 Canada 0 1 1 UK 0 0 0 USA 3 4 0 Model X 75D Model X 90D Model X P90D Asia Pacific &amp; Europe (excl UK) 4 11 1 Canada 0 0 0 UK 0 0 0 USA 0 5 0 Unspecified 85 kWh Asia Pacific &amp; Europe (excl UK) 24 Canada 0 UK 0 USA 0 Chi-square is as simple as running chisq.test() on the two-way table. chisq.test(tbl) Pearson&#39;s Chi-squared test data: tbl X-squared = 254.16, df = 69, p-value &lt; 2.2e-16 Tests for proportions require the prop.test command and require just inputting the desired counts and/or population proportions. We won’t do an application here, but if 23 of 120 have a trait and we would like to see if the proprtion is significantly greater than 0.15, we might use the command prop.test(23,120, p=0.15, alternative = &quot;greater&quot;) 1-sample proportions test with continuity correction data: 23 out of 120 X-squared = 1.3235, df = 1, p-value = 0.125 alternative hypothesis: true p is greater than 0.15 95 percent confidence interval: 0.136025 1.000000 sample estimates: p 0.1916667 As with the t-tests, notice that the confidence interval is an added bonus, but requires the two-sided option. A two-sample test for proportions may be run similarly with a slight modification: prop.test(c(31,40),c(60,85), alternative = &quot;greater&quot;) 2-sample test for equality of proportions with continuity correction data: c(31, 40) out of c(60, 85) X-squared = 0.14289, df = 1, p-value = 0.3527 alternative hypothesis: greater 95 percent confidence interval: -0.1066671 1.0000000 sample estimates: prop 1 prop 2 0.5166667 0.4705882 where the first list specifies the counts with the trait in each of the two groups and the second list consists of the sample sizes for each of the two groups. "],
["r-across-the-curriculum.html", "4 R across the curriculum 4.1 Pedagogy for Programming 4.2 Examples, assignments, and projects 4.3 R Packages for Teaching and Learning", " 4 R across the curriculum 4.1 Pedagogy for Programming Twitter @Allison_Horst 4.1.1 Why is R so scary? For students and first time users, R can be scary because it is different from most of the technology we engage with daily. Our smartphones and operating systems are structured to make us passive users of technology - the programs makes many of the decisions for us. In contrast, R can only do what it is told and the instructions provided must be exact (including punctuation, capitalization, and grammar). The challenges of learning programming often lead students to think they are simply not programmers. Just as we have to quash the “I’m not a math person” myth, we must also quash the “I’m not a programmer” myth. Here is some encouragement from the creator of RStudio and the tidyverse himself: It’s easy when you start out programming to get really frustrated and think, “oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again. ~Hadley Wickham Also, here is a great video of Hadley Wickham on Twitter discussing the initial stages of learning R programming. Students will need encouragement (just as you will) to persevere. Once the power of R is realized, especially for reproducibility, students tend to want to learn more! 4.1.2 Getting Started with R in the Classroom As instructors, we must always be aware of the cognitive load of our students. To learn both R and Statistics at the same time can be a challenge for students. Information processing model of memory Students often assume they will have total recall once they see something, but they will lose information without rehearsal and retrieval. Patience is key to learning R and unfortunately, to learn patience in programming usually means experience some form of trial first. 4.1.2.1 The First Week To get students to learn R, they must use it regularly both in and out of the classroom. So start using R the very first day (or at least week) of classes. The time taken from class to make sure students have started on the right track with R is worth it in the long run. Remember statistical computing is still an important part of statistics education so it deserves time within the classroom. Here are some tips for getting started with R in the classroom: Don’t be afraid of live coding, even if you make a mistake you can demonstrate how you solve the error or issue by modeling your cognitive process out loud. Be sure to model and talk your cognitive process as you code for students and don’t skip steps. Consider using post-its or other signals for students to get help or indicate they have successfully completed a task. Take time to discuss output, even the output you won’t use, as it is not always intuitive. Avoid the black box and show in class how R produces output that matches with the computations/methods they have seen in class (and how it differs). Create or use existing Videos/Demos/Tutorials online as resources for the students. Make students think before they program. For example, have them consider the final graph they wish to create before they code or consider what the output should look like before they try to run any code. 4.1.2.2 Paired Programming In class, access to technology can be limited and students often need to share computers. There is strong evidence that students should participate in paired programming regardless (see Pair Programming for Data Science and Statistics). The biggest challenge with students working in pairs or groups is that often they default to the “strongest” programmer in the group who takes over and does not support the learning of the other group members. Therefore, we need to provide participation structures to be sure all students can learn to program together. To support student learning, we’ve adapted a method called “Think Aloud Paired Problem Solving” from Reading Apprenticeship to be used in paired programming. Students use the R Task Card as a guide and instructors assign roles and time limits to each role so that students rotate between being the listener and the problem solver. The listener is the programmer and can only act at the instruction of the problem solver. You can model this with your students, where you act as the listener and you can only act at the instruction of the students while you live code. 4.1.2.3 Deciphering Errors One of the biggest challenges students experience in learning to use R are error messages. They may experience error messages in several ways: Warnings when code still produces output Error messages when R code is not correct Error messages when RMarkdown documents cannot knit For warnings (#1) sometimes it is just letting the user know some function made decisions, such as dropping NA’s or using an exact versus asymptotic method for a p-value calculations. Other times, it can indicate a major issue with the code formulation, but that is usually when dealing with more advanced statistical methods. For error messages when RMarkdown documents cannot knit (#3) it may be due to R code, markdown, or YAML code issues. The most common errors for students are They loaded the data or packages into the RStudio environment, but not within the RMarkdown environment. So their code works, but once they try to knit the RMarkdown document the data/packages are not found because RMarkdown acts as its own environment (so that it is reproducible). R code errors within the RMarkdown document. RMarkdown log files will indicate what line of the document the error occurred and will often provide some indication of why the error occurred. Sometimes the document line number is not exact and the error is further down in the document, but at least it shows you where to start looking. For R code error messages, the most common mistakes are misspelling, punctutation (commas, parenthesis), and capitalization. Let’s see if we can decipher some errors in the following RMarkdown document so that we can knit it into a final document. 4.1.3 Additional Resources With the data science and technology boom there are has been more research and emphasis on evidence based practices in teaching programming and technology. Here are a few that might be helpful. Teaching Tech Together (book) Slides for RStudio Instructor Training The Carpentries Instructor Training Modules Teach Data Science Summer 2019 Blog 4.2 Examples, assignments, and projects 4.2.1 First labs General helpful principals: * make sure they are successfull right away * make it a useful tool so they want to use it * reflect regularly * timeliness and integration are key * integrated into class activities or distinct labs * demonstrate it for them (along with all of your errors, they need to see how to make mistakes and how you fix them) * biggest hurdle is usually their fear as it isn’t like anything they have done. Here is an example of how I begin the first two days of an introductory statistics course (simple and quick to get results): Day 1 Intro Lab And the corresponding data Fakedata.csv Day 2 Lab 1 4.2.2 In-class usage Using R during class. When first teaching the Central Limit Theorem I enter these while explaining what is happening # skewed population dataset &lt;- 78-rexp(1000,1/2) # skewed with not as sharp of a drop off dataset = cbind(78-rexp(5000,1/5),78+rexp(200,1/1.1)) # bimodal population dataset = c(rnorm(1000,80,20),rnorm(400,10,10)) mean(dataset) median(dataset) hist(dataset)#,xlim = c(70,80)) k &lt;- 1000 # number of samples n &lt;- 50 # sample size ran_samples &lt;- matrix(sample(dataset, k*n, replace = TRUE), nrow = k, ncol = n) head(ran_samples) sample_means &lt;- apply( ran_samples, 1, mean) head(sample_means) hist(sample_means, xlim = c(20,100)) 4.3 R Packages for Teaching and Learning 4.3.1 Base R vs. Packages for Learning There are a lot of options in base R, but often they can be clunky and a bit of a challenge for students. Download the Packages for Learning Notebook Let’s look at an example (you can find the data called KingCounty2011.csv in linked here: In 2001, a sample of 2500 births from King County, Washington contained information on both the mother and the infant at birth. king&lt;-read.csv(&quot;Data/KingCounty2001.csv&quot;) Suppose we want to compare the birth weight (bwt) of a baby between mothers who smoke (Y) versus do not smoke (N) (smoker). In base R, here is what the code would look like: mean(king$bwt[king$smoker==&quot;Y&quot;]) #smoke [1] 3185.737 mean(king$bwt[king$smoker==&quot;N&quot;]) #do not smoke [1] 3431.201 How would we calculate the standard deviation as well? sd(king$bwt[king$smoker==&quot;Y&quot;]) #smoke [1] 583.4798 sd(king$bwt[king$smoker==&quot;N&quot;]) #do not smoke [1] 553.8304 It quickly becomes cumbersome to do this for multiple summary statistics. So what if there is a better way? 4.3.2 Package mosaic The mosaic package was developed by Randall Pruim, Danny Kaplan, and Nicholas Horton. The goal of Project mosiac is to support the learning of R in colleges and universities. Let’s try our previous problem using functions in mosaic. First, install the package if you haven’t done so already. install.packages(&quot;mosaic&quot;) Now, before we load the package, let’s take a peak at the mean() function in base R. What error results? mean(king$bwt~king$smoker) argument is not numeric or logical: returning NA[1] NA What does that error message mean? Now load the mosaic package and note the message provided when loaded: library(mosaic) Notice that it states that The following objects are masked from package:base: max, mean, min, prod, range, sample, sum Package Mosaic overwrites several of the base package functions with new functions of the same name to make them adaptable to the formula notation. We can now run our mean() function (overwritten by mosaic) mean(bwt~smoker, data=king) N Y 3431.201 3185.737 Many of the summary statistic functions of base R will now work in function form. mosaic also adds new functions, such as favstats favstats(bwt~smoker, data=king) smoker min Q1 median Q3 max mean sd n missing 1 N 255 3118.0 3459 3770 5175 3431.201 553.8304 2325 0 2 Y 414 2856.5 3275 3544 4508 3185.737 583.4798 175 0 In addition, it allows for some simple graphics that allow faceting: histogram(~bwt|smoker, data=king) and easy bar graphs without the need to create a count table: bargraph(~smoker, data=king) and overlay summary values: histogram(~bwt, v=2500, data = king) 4.3.3 Package ggformula Just like mosaic, ggformula was written to get students doing powerful visualization quickly, without having to learn the ins and outs of ggplot2 or even base R. While mosaic has some graphing functionality, ggformula serves as an overlay for ggplot2, allowing the user to create quality graphics and to support multivariate reasoning via formulas. To learn more, check out the vignette from the ggformula package. Install the package and load it into R. #install.packages(&quot;ggformula&quot;) library(ggformula) You can easily “pipe” using the %&gt;% symbol to overlay two graphs and you can use many of the ggplot2 arguments within the ggformula functions. For example: gf_boxplot(bwt~smoker, data=king) %&gt;% gf_violin(bwt~smoker, data=king, fill=~smoker, alpha=0.3) Try out a few other plots using the King County birth weight data and ggformula. To learn more about the pipe %&gt;% in R, read the Pipes chapter in R for Data Science. 4.3.4 Package infer The objective of the infer package is to perform statistical inference using an expressive statistical grammar that mimics the tidyverse design framework. The goal is to have students run a hypothesis test by using functions that follow these steps: infer Grammar for Inference Install the package if you haven’t done so already. install.packages(&quot;infer&quot;) and load the infer package: library(infer) Let’s look at an example, to compare the mean birth weights for infants born to smokers and non-smokers. First, let’s calculate the test statistic, what would we want to compare? king %&gt;% specify(bwt ~ smoker) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;Y&quot;, &quot;N&quot;)) -&gt; d_hat Next we generate data under the null hypothesis and calculate the test statistic under the null hypothesis to determine the “null distribution” of the null hypothesis. What is our null hypothesis? \\(H_0: \\mu_{smoker} = \\mu_{nonsmoker}\\) \\(H_0: \\mu_{smoker} \\neq \\mu_{nonsmoker}\\) king %&gt;% specify(bwt ~ smoker) %&gt;% hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 1000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;Y&quot;, &quot;N&quot;)) -&gt; null_dist Finally, we can visualize the null distribution and p-value. What conclusion should we draw from our inference? visualise(null_dist) + shade_p_value(obs_stat = d_hat, direction = &quot;two_sided&quot;) You can learn more about the infer package for different tests by reading the infer vignettes. 4.3.5 Packages for Learning R - Swirl swirl is a package designed to let you learn R within R. Check out the Swirl webpage to learn more. To get started, you just have to load the library (after you install it of course). install.packages(&quot;swirl&quot;) library(swirl) "],
["teaching-students-and-you-how-to-get-help.html", "5 Teaching students (and you) how to get help", " 5 Teaching students (and you) how to get help We just practiced one of the most challenging aspects for students: debugging errors! Here are some more ways to get help: Searching for help: Using ?? Using ? browseVignettes() Search for a descriptions of the task, not your specific case (students have to be reminded of this) Stack Overflow RSeek.org One of the wonderful things about R is all of the publicly available support. There are nearly limitless places to go. Here are a few links that we find helpful. RStudio Cheatsheets ggplot Cheatsheet R Graphics Gallery "],
["untidy-data.html", "6 Untidy Data 6.1 Tidy Data 6.2 Miscellany on data types in R", " 6 Untidy Data 6.1 Tidy Data “Happy families are all alike; every unhappy family is unhappy in its own way.” –– Leo Tolstoy “Tidy datasets are all alike, but every messy dataset is messy in its own way.” –– Hadley Wickham R works best with “tidy data”. There are three interrelated rules which make a dataset tidy: Each variable must have its own column. Each observation must have its own row. Each value must have its own cell. R for Data Science Most data does not start out “tidy”. Fortunately, the tidyverse was designed to help with the process of turning messy data into tidy data. Packages such as dplyr, tidyr, lubridate, forcats, and stringr allow the user to clean up data and eventually turn it into nice and tidy data. It would be impossible to teach you how to clean data in all circumstances in the 15 minutes we have, but I wanted to overview the grammar of data cleaning for you. The functions in tidyr and dplyr mimic the grammar of data cleaning to make it easy to learn. Select - choose specific columns Filter - choose specific rows Sort/Arrange - order the rows in the columns Mutate - add a new column from Winona State Join - join two data tables together from Winona State Gather - gather column names that are values instead of variables into a single column Spread - spread out observation values to new column variables with they are spread across multiple rows from Winona State The best way to learn to clean data is to clean data! I highly recommend working through R for Data Science and the exercises included (here are the solutions). In addition to navigating the shape of the data, there are often fun surprises within the data even with technically “tidy”. You might have character strings that are messy and contain information that needs to be extracted (use stringr), or dates (use lubridate), or that need to be specified as ordered factors (use forcats). base R will often make decisions for you when reading in data as well. To avoid that, use readr to specify variable/data types when reading in the data to save a headache later! 6.1.1 Example - Cleaning the Tesla Data The Tesla data was actually “tidy” in format, but had a lot of dates (in multiple formats) and strings that needed some massaging. Here is what I did (more could be done!) to get the data ready for your use. library(readr) library(dplyr) library(stringr) library(lubridate) tesla&lt;-read_csv(&quot;Data/TeslaBatterySurvey2018.csv&quot;) tesla %&gt;% rename(BatteryAgeDays=`Battery AgeDays`) %&gt;% mutate(DailyChargeLevel=as.numeric(str_sub(DailyChargeLevel,1,2))) %&gt;% mutate(Location=str_replace_all(tesla$Location,&quot;uK&quot;, &quot;UK&quot;)) %&gt;% mutate(ReadDate=parse_date_time(ReadDate, c(&quot;%d-%b-%y&quot;, &quot;%m/%d/%Y&quot;, &quot;%d. %b %Y&quot;),exact=TRUE)) %&gt;% mutate(ManufactureDate=parse_date_time(ManufactureDate, c(&quot;%d-%b-%y&quot;, &quot;%m/%d/%Y&quot;, &quot;%d. %b %Y&quot;),exact=TRUE)) %&gt;% mutate(ModelXS=str_split(Model,&quot; &quot;, simplify = TRUE)[,2], ModNum=str_split(Model,&quot; &quot;,simplify = TRUE)[,3]) %&gt;% write_csv(&quot;cleanTeslaBattery.csv&quot;) newtesla&lt;-read.csv(&quot;cleanTeslaBattery.csv&quot;) str(newtesla) &#39;data.frame&#39;: 1339 obs. of 20 variables: $ Location : Factor w/ 4 levels &quot;Asia Pacific &amp; Europe (excl UK)&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... $ ManufactureDate : Factor w/ 388 levels &quot;2012-09-12T00:00:00Z&quot;,..: 233 121 256 215 191 304 274 176 349 NA ... $ ReadDate : Factor w/ 769 levels &quot;2014-03-27T00:00:00Z&quot;,..: 169 219 444 457 472 477 542 535 539 611 ... $ AgeInDays : int 45 520 387 556 653 187 475 839 36 42965 ... $ Model : Factor w/ 24 levels &quot;Model 3 LR&quot;,&quot;Model S 100D&quot;,..: 9 3 10 9 9 9 10 9 4 8 ... $ MileageKM : int 2800 10500 34653 45959 37895 16800 49129 49900 2271 3000 ... $ MileagePerDay : num 60.9 20.2 89.3 82.5 57.9 ... $ MaxRangeKM : int 246 180 256 231 238 242 266 239 205 239 ... $ ReplacementBatt : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 1 1 1 1 1 1 ... $ MileageSinceNewKM: int 2800 10500 34653 45959 37895 16800 49129 49900 2271 3000 ... $ BatteryAgeDays : int 46 521 388 557 654 188 476 840 37 NA ... $ WattHoursPerKM : num 323 353 345 379 358 318 320 323 NA 305 ... $ OriginalRangeKM : int 249 180 267 249 249 249 267 249 207 242 ... $ SuperchargeFreq : Factor w/ 8 levels &quot;a few times a year&quot;,..: 6 5 2 8 1 3 8 3 NA NA ... $ MaxChargeFreq : Factor w/ 8 levels &quot;a few times a year&quot;,..: 3 1 3 5 3 1 4 1 NA NA ... $ RunToEmptyFreq : Factor w/ 7 levels &quot;a few times a year&quot;,..: 4 4 1 3 3 3 3 3 NA NA ... $ DailyChargeLevel : int 80 70 90 70 80 90 80 80 NA NA ... $ Cycles : num 11.7 63.4 156.6 231.8 179 ... $ ModelXS : Factor w/ 4 levels &quot;3&quot;,&quot;85&quot;,&quot;S&quot;,&quot;X&quot;: 3 3 3 3 3 3 3 3 3 3 ... $ ModNum : Factor w/ 18 levels &quot;100D&quot;,&quot;60&quot;,&quot;60D&quot;,..: 8 2 9 8 8 8 9 8 3 7 ... 6.2 Miscellany on data types in R R has several built-in data types that you may find useful: Vector, like arrays in other languages, a collection of entries, each with the same type of data. 1:4 [1] 1 2 3 4 Lists with mixed data types list(&quot;28&quot;,14) [[1]] [1] &quot;28&quot; [[2]] [1] 14 Matrices for storing data of all the same type: A = matrix( c(1, 3, 5, 9, 2, 1), # the data elements nrow=2, # number of rows ncol=3, # number of columns byrow = TRUE) # specify to fill in across the rows or down the columns Note that we have been using data frames that can be built from the ground up. weight = c(55,33,21,19) height = c(67,41,35,24) pet = c(&quot;cat&quot;,&quot;dog&quot;,&quot;cat&quot;,&quot;lizard&quot;) dat = data.frame(height,weight, pet) summary(dat) height weight pet Min. :24.00 Min. :19.0 cat :2 1st Qu.:32.25 1st Qu.:20.5 dog :1 Median :38.00 Median :27.0 lizard:1 Mean :41.75 Mean :32.0 3rd Qu.:47.50 3rd Qu.:38.5 Max. :67.00 Max. :55.0 Note that entries in data frames can be accessed much as the way they are in other languages. Try each of the following. What do each of them do? dat[1,2] dat[,2] dat[2:3,] dat[c(1,4),] dat[,&quot;weight&quot;] dat[,c(&quot;height&quot;,&quot;pet&quot;)] dat[-2,] One of the other incredibly handy features is that rows can also be selected based on various criteria. We can select the rows where the pet is a cat using the command or the weight of the rows where the pet is a cat using the following two commands: dat[dat$pet==&quot;cat&quot;,] height weight pet 1 67 55 cat 3 35 21 cat dat[dat$pet==&quot;cat&quot;,&quot;weight&quot;] [1] 55 21 R also casts vectors to apply arithmetic operations to lists and also allows dynamic variable assignment in data frames. Below we will rescale the weight by multiplying by 16 and save it in the column new height dat$newheight = dat$height *16 dat height weight pet newheight 1 67 55 cat 1072 2 41 33 dog 656 3 35 21 cat 560 4 24 19 lizard 384 This can be handy for normalizing and transforming data. Note there is also a scale function for rescaling data. "]
]
