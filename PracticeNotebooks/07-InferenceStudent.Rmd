# Statistical Inference

In this section we will cover some of the basic tools for statistical inference covered in an introductory statistics class.

## ANOVA
We will demonstrate the use of ANOVA, but *t*-tests are quite similar.

    Teaching Tip:  When teaching non-majors incorporating data from the research of faculty teaching courses from other disciplines can increase student engagement and course relevance.
    


For this section we are going to work with a dataset from a cancer drug development project that is part of a biology faculty member's ongoing research at our campus, the data came from one of the student projects.  Below is an image of one of the tumors.
![CancerTumor](Images/Tumor.jpg)

The measurements in the file are the percent of tumor growth under various drug treatments. [TumorGrowth.csv](Data/Tumor.csv).  Load the data now and inspect the dataset.
```{r}

```


Construct a graphical summary of your data using one of the tools from earlier.

```{r}

```

We will also construct a numerical summaries of each group using the 
 `doBy` package.  Install and load `doBy` now.
```{r }

```

For this I define a helper function:
```{r}
msd = function (x) {c(m = mean(x), stdev = sd(x))}
```

We will now use the `summaryBy` function and our defined function `msd`.  Run the following block.  What does it produce?

```{r }
summaryBy(Growth ~ Treatment, data = Tumor, FUN = msd )

```
To run an ANOVA use the command `aov()` by specifying the relationship and the `data`, as you did for summarizing the data. 

```{r}

```
Note that there is something missing that most intro stats students are asked for, what is it?

This can be fixed by wrapping the `aov` command with a `summary()`.  **Try it**.
```{r}

```


Post-hoc tests can be run by saving the ANOVA model to a variable and then passing it to `TukeyHSD()`.

Try it here:

```{r}

```
There are other functions for the other types of post-hoc tests.


## Testing for Proportions
We will return to the `cleanTeslaBattery` data.  Suppose we want to look at the relationship between `Location` and `Model.`  

Create a two-way table and a bar plot for these variables.
```{r }


```

```{r}

```

Chi-squared is as simple as running `chisq.test()` on the two-way table.
```{r}

```

Tests for proportions require the `prop.test` command and require just inputting the desired counts and/or population proportions.  We won't do an application here, but if 23 of 120 have a trait and we would like to see if the proprtion is significantly greater than 0.15, we might use the command
```{r}
prop.test(23,120, p=0.15, alternative = "greater")
```

As with the t-tests, notice that the confidence interval is an added bonus, but requires the two-sided option.

A two-sample test for proportions may be run similarly with a slight modification:
```{r}
prop.test(c(31,40),c(60,85), alternative = "greater")
```

where the first list specifies the counts with the trait in each of the two groups and the second list consists of the sample sizes for each of the two groups.

## Linear Regression

Let's go back to the Tesla Battery Data from earlier.  We did linear regression when we added the regression line earlier, but now we will explore some of the other available tools with regression.

```{r}
cleanTeslaBattery = read.csv("Data/cleanTeslaBattery.csv")
```

Implement the linear model from before to look at the relationship between the Mileage (`MileageKM`) and Watt Hours Per KM (`WattHoursPerKM`) and assign the model to the variable `mod`

```{r}

```

We can also easily inspect the residuals by calling the `residual()` function on the model.  Try it:
```{r}

```

Additionally transforms of any of the variables can be performed in the following way:


```{r}
lm(WattHoursPerKM ~ log(MileageKM), data = cleanTeslaBattery)
lm(sqrt(WattHoursPerKM) ~ MileageKM, data = cleanTeslaBattery)
```

Finally, we left out the correlation coefficient.  The call for the correlation coefficient is a little different as it doesn't use relations `cor(x,y, use = "pairwise.complete.obs", method = "pearson")`.  Try the command here for the Mileage and Watt Hours Per KM.

```{r}


```

Note that the `use` option has been specified to omit pairs of correlations where ther is an NA, and the `method` controls the type of correlation.



## t-tests
Here is a very quick overview of t-tests.  We are going to take a look at the difference in weight gain be smoking and non-smoking mothers in Kings County.  Load the dataset

```{r }
Kings <- read.csv("Data/KingsCounty2001.csv") 
```
Take a look at the relationship between `smokeN` and `wgain`.
```{r}
boxplot(wgain ~ smokeN, data = Kings )
```

two-sample *t*-test syntax is nearly identical to ANOVA syntax, except we need to replace the `aov` wit `t.test` and specify the type of alternative, either "greater", "less" or "two.tailed", using the `alternative` option.

```{r}
t.test(wgain ~ smokeN, data = Kings, alternative = "greater")
```
Note that confidence intervals are included, but the alternative should be "two.sided."


One-sided *t*-tests require specifying only a single quantitative variable and also specifying the value from the null hypothesis.  An example for testing that the mean `wgain` is different from 9.4 is

```{r}
t.test(Kings$wgain, mu = 9.4, alt = "two.sided")
```

Other options like the `conf.level` are described under the help for the function.

Try computing a 90% confidence interval for the mean `gest`.

```{r}

```


## Paired t-test
Paired t-tests require data in the wide format, that is two columns side by side, perhaps like this
```{r}
pairdat = data.frame(pre=c(23,20,30,29),post=c(25,21,27,31))
pairdat
```
Note this is for example only, not for validity.
```{r}
t.test(pairdat$pre, pairdat$post, paired=TRUE)
```



